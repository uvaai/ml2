# Neural Networks

These videos by Andrew outline what a neural network looks like, and give some
good intuitions on why it is such a useful model. They should be a good first
introduction into what neural networks are exactly. These videos do not yet
cover how exactly to train a neural network.

#### A note on notation

**Important:** This video use a slightly different notation than we use in
the course, meaning the equations for Logistic Regression won't look exactly
like the ones you're familiar with. The following page briefly describes the
changes in notation, so have a look there before watching the video:
[neural_network_notation](nn_notation.pdf)

### Neural Network Representation: Non-linear hypothese

![embed](https://youtube.com/embed/SGEroEKFbnY)

## Backpropagation: Training a neural network

The algorithm to learn the weights of a neural network based on training data
is called *backpropagation* and is quite a difficult algorithm to completely
understand. Introducing backpropagation in its general form will be one of the
main topics of the *next* neural networks module.

Here, for a high level overview of what backpropagation tries to do and
how neural networks end up being used in practice, we'll refer to these
introductory videos by *3blue1brown*.

### Deep Learning: But what is a Neural Network?

![embed](https://youtube.com/embed/aircAruvnKk)

### Deep Learning: Gradient descent, how neural networks learn

![embed](https://youtube.com/embed/IHZwWFHWa-w)


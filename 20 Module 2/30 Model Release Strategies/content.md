
# Model Release Strategies

This module you've started to learn about neural networks, which are currently
most well known and impactful machine learning models by far. Although all
neural network models share the same basic design covered this module, there
are many, many different types and variants of neural networks. These networks
are each designed to solved different problems, which means they impact
different areas of research and sometimes even different areas of society, when
they produce greatly improved results.

In 2019 OpenAI developed a new transformer language model (this is one of these
many types of neural networks) called *GPT-2*. This model was trained using
very large volumes of text on the task of simply predicting the next word given
some sequence of words before it. The *GPT-2* is suprisely effective at this
task and can be used to generate pretty convincing fake text.

When the model was first announced by OpenAI, they made the somewhat
controversial decision to not release model to public, due to the risk of this
model being used for malicious purposes.  Start by reading their initial blog
post containing the announcement and their reasoning for not releasing the
model. Make sure to check out the samples of text generated by *GPT-2* there
too:

[OpenAI - Better Language Models](https://openai.com/blog/better-language-models/)

As mentioned, whether or not this was actually a safer strategy was
controversial and there were plenty of opinions advocating the release of the
GPT-2 model publicly. Read the blog post by Hugh Zhang from the Stanford
Natural Language Processing Group below:

[Hugh Zhang - OpenAI: Please Open Source Your Language Model](https://thegradient.pub/openai-please-open-source-your-language-model/)

OpenAI did a follow-up post after 6 months, detailing their thoughts on the
staged release strategy as being a key foundation of for responsible
publication in AI. Read the blog post linked below:

[OpenAI - GPT-2: 6-Month follow-up](https://openai.com/blog/gpt-2-6-month-follow-up/)

Some researcher took a different approach, most notably the team from the
University of Washington behind the Grover model. Read the blog post by Rowam
Zellers on why they decided to release this model to public instead:

[Rowan Zellers - Why We Released Grover](https://thegradient.pub/why-we-released-grover/)

As you can see, there is no clear-cut answer to question of what is the best
release strategy for a powerful machine learning model. In a sense, the *GPT-2*
model was an interesting trial for such a release strategy as the model was
good, but most results where still selected by humans from a group of possible
generated results, meaning to model was not yet advanced enough to always
genreate convincing examples.

For this writing assignment, you are asked to argue for a specific release
strategy for a hypothetical new language model that consistently produces such
good results it is almost indistinguishable from human writing. You can choose
to have a some form of a staged release or just release the model publicly
right away. You may even proposed some alternate release strategy, as long as
whatevery strategy you pick for this hypothetical model, is supported by
arguments based your impressions from reading the 4 articles linked above.

[You can experiment with a basic version of GPT-2 for yourself here](https://bellard.org/textsynth/)



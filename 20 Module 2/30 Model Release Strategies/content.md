
# Model Release Strategies

> *Note:* A large part of this assignment was originally written before the
release of *ChatGPT* in November of 2022. This can make a discussion on the
*potential* release of an effective large language model seem a bit dated, as
ChatGPT is already proving to have [a large impact in many areas](https://blog.gitnux.com/chat-gpt-statistics/).
However, exactly because of that impact, it is still very relevant to consider
the different ways you can release powerful AI models into the world. The GPT
models discussed below are actually the predecessors of ChatGPT, and so make
for an interesting case study.

This module you've started to learn about neural networks, which are currently
the AI models with the biggest impact by far. Although all neural network
models share the same basic design, there are many, many different types and
variations of neural networks. These networks are each designed to solve
different problems, which means they impact different areas of research and
sometimes even different areas of society, when they produce greatly improved
results.

In 2019 OpenAI developed a new transformer language model (this is one of these
many types of neural networks) called *GPT-2*. This model was trained using
very large volumes of text on the task of simply predicting the next word,
given the sequence of words before it. *GPT-2* is surprisingly effective at
this task and can be used to generate pretty convincing fake text from a
specific starting prompt.

When the model was first announced by OpenAI, they made the somewhat
controversial decision to *not* release this model publicly, due to the risk of
the model being used for malicious purposes. Start by reading the initial blog
post by Open AI containing the announcement and their reasoning for not
releasing the model. Make sure to check out the samples of text generated by
*GPT-2* provided there too:

[OpenAI - Better Language Models](https://openai.com/blog/better-language-models/)

As mentioned, whether or not this was actually a safer strategy was
controversial and there were plenty of opinions advocating the release of the
GPT-2 model publicly. Read the blog post by Hugh Zhang from the Stanford
Natural Language Processing Group below:

[Hugh Zhang - OpenAI: Please Open Source Your Language Model](https://thegradient.pub/openai-please-open-source-your-language-model/)

OpenAI did a follow-up post after 6 months, detailing their thoughts on the
staged release strategy for *GPT-2* and it serving as a foundation of
responsible publication in AI. Read the blog post linked below:

[OpenAI - GPT-2: 6-Month follow-up](https://openai.com/blog/gpt-2-6-month-follow-up/)

Some researchers took a different approach, most notably the team from the
University of Washington behind the Grover model. Read the blog post by Rowan
Zellers on why they decided to release this model publicly instead:

[Rowan Zellers - Why We Released Grover](https://thegradient.pub/why-we-released-grover/)

As you can see, there is no clear-cut answer to the question of what the best
release strategy for a powerful machine learning model is. In a sense, the
*GPT-2* model was an interesting trial for such a release strategy, as the
model was good, but most results were still selected by humans from a group of
possible generated results, meaning the model was not yet advanced enough to
always generate convincing examples.

[You can also experiment with a basic version of GPT-2 for yourself here](https://bellard.org/textsynth/)

For this writing assignment, you are asked to argue for a specific release
strategy for a hypothetical new language model that consistently produces very
convincing fake text, which is indistinguishable from human writing. You can
choose to have some form of a staged release or just release the model publicly
right away. You may even propose some alternate release strategy, as long as
whatever strategy you pick for this hypothetical model is supported by
arguments based on your impressions from reading the 4 articles linked above.

> *Note:* OpenAI has now created a very powerful large language model
called ChatGPT, which already produces very convincing fake text, but it can
still be detected as such some of the time. OpenAI, which was originally
founded as a non-profit with the explicit goal of open and collaborative AI
research [in the way that it is most likely to benefit humanity as a
whole](https://openai.com/blog/introducing-openai), ended up choosing the
following release strategy for these ChatGPT models: an unreleased model and
training set, with limited free access to producing outputs for prompts, while
monitizing access during peak hours and when using more advanced features, like
their newly released GPT-4 model. For this assignment, assume the hypothetical
new language model is another large leap in improvement over ChatGPT's output,
and so is completely indistinguishable from human writing.

Your assignment should be long enough to make a clear and cohesive argument for
your point of view. In general, this tends to correspond with around 500 words. 
The minimum requirement for the assignment is 350 words.

#### Peer review

You are encouraged to swap writing assignments with other students, read them
and share feedback with each other, both on the contents of the arguments and
the structure of the writing. Writing a good text can be difficult and,
especially after you rewrote something a couple of times, other people will
generally see improvements that you can't spot anymore. So, make use of that
and help each other out by exchanging feedback.


# Logistic Regression

This week we'll continue with more videos from Andrew Ng's machine learning course on Coursera. Before we start with Logistic Regression, we will first freshen up our knowledge on the definition of machine learning. The last video you have already seen, but we have included it again this week, as it is very important for the model we will build in this week's programming exercises.

### What is machine learning

![embed](https://www.youtube.com/embed/PPLop4L2eGk)

### Logistic Regression: Classification

![embed](https://youtube.com/embed/-la3q9d7AKQ)

### Logistic Regression: Hypothesis Representation

![embed](https://youtube.com/embed/t1IT5hZfS48)

### Logistic Regression: Decision Boundary

![embed](https://youtube.com/embed/F_VG4LNjZZw)

### Logistic Regression: Cost Function

![embed](https://youtube.com/embed/HIQlmHxI6-0)

### Logistic Regression: Simplified Cost Function and Gradient Descent

![embed](https://youtube.com/embed/TTdcc21Ko9A)

### Logistic Regression: MultiClass Classification OneVsAll

![embed](https://youtube.com/embed/-EIfb6vFJzc)

### Recap: Feature Scaling

You have already seen this video in week 5 of this course. We will discuss and apply feature scaling in this week's notebook, so if you are unsure on when and why you would apply feature scaling, please watch this video again.

![embed](https://youtube.com/embed/r5E2X1JdHAU)


# Neural Networks (cont.)

In the previous module you've learned about what a neural network is and how it
can be used to compute predictions. In this module we'll build on that and
cover a lot more of the theory of neural networks, which has been divided into
3 parts.

The first part covers backpropagation, which is the fundamental algorithm all
neural networks use to compute the gradient of the weights of the network and
apply gradient descent. The [theory videos](/module-3/learning-network-weights)
will introduce the algorithm and in the [programming notebook](/module-3/backpropagation)
you'll add backpropagation to a neural network implementation.

The second part covers some of the most common extensions of neural networks,
which allow for building much deeper networks, i.e. with many more hidden
layers. The [theory videos](/module-3/building-deeper-networks) will introduce
3 extensions and in the [programming notebook](/module-3/activation-functions)
you'll implement these extensions yourself.

The last part covers some practical tips for applying neural networks to your
own data and how to deal with common problems like underfitting or overfitting.
The [theory videos](/module-3/applying-neural-networks) will introduce
regularization and cover how to choose between different solutions for common
problems.


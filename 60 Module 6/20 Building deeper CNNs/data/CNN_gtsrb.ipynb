{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The German Traffic Sign Recognition Benchmark\n",
    "\n",
    "For this assignment we'll work with the German Traffic Sign Recognition Benchmark, which is benchmark for classifying images of traffic signs as one specific type of sign, for example a stop sign. Clearly this type of classification is useful to be able to do for autonoumous driving vehicles, so they know to come to full stop at certain intersections. Download the training data for yourself [here](https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB-Training_fixed.zip).\n",
    "\n",
    "Unzip the file and take a look at images in the different folders there. Also take a look at the *Readme.txt* and make sure you understand the structure of the classification task before starting. Below is a cell to download the training and testing data for this benchmark onto this machine.\n",
    "\n",
    "*Note:* Remember to run this notebook as [Google Colab](https://colab.research.google.com) with GPU hardware acceleration enabled! This will make training your network *much* faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB-Training_fixed.zip\n",
    "!unzip -q GTSRB-Training_fixed.zip\n",
    "\n",
    "!wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Online-Test-Images-Sorted.zip\n",
    "!unzip -q GTSRB_Online-Test-Images-Sorted.zip\n",
    "\n",
    "!rm -rf GTSRB/Online-Test-sort/Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some code we've already provided to load the data. It is not required you understand what the functions in this cell do exactly. The functions mostly deal with the slightly more complicated loading of the images, as they're all in different folders and have a `.ppm` format. Additionally, it resizes all images to a standard *32 x 32* size, so they'll all fit into a neural network with the same input layer size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def build_image_path_list(data_dir):\n",
    "    image_path_list = []\n",
    "    for root, dirs, files in list(os.walk(data_dir))[1:]:\n",
    "        image_path_list.extend([(os.path.join(root, f), int(root.rsplit('/', 1)[1]))\n",
    "                                for f in files if f.endswith('.ppm')])\n",
    "    return image_path_list\n",
    "    \n",
    "def load_data(data_dir, size=32):\n",
    "    image_list, target_list = [], []\n",
    "\n",
    "    for image_path, target in build_image_path_list(data_dir):\n",
    "        image_list.append(cv2.resize(cv2.imread(image_path), (size, size)))\n",
    "        target_list.append(target)\n",
    "\n",
    "    return (np.array(image_list), np.array(target_list))\n",
    "\n",
    "train_images, train_labels = load_data('GTSRB/Training')\n",
    "test_images, test_labels = load_data('GTSRB/Online-Test-sort')\n",
    "\n",
    "print(f'Training images loaded: {train_images.shape}')\n",
    "print(f'Training labels loaded: {train_labels.shape}')\n",
    "print(f'Testing images loaded: {test_images.shape}')\n",
    "print(f'Testing labels loaded: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you'll have to build and train a deep convolutional neural network yourself for this GTSRB data set. The goal is simply to get as high as possible accuracy on the provided test set, using only the training data to learn. You may of course reuse any code you might find useful from the CIFAR notebook for this, and are also free to look up any other functions or classes you might want to try from the [TensorFlow Keras API](https://www.tensorflow.org/api_docs/python/tf/keras/) (which is what we've used for the CIFAR notebook too).\n",
    "\n",
    "As you try different versions of your network, you should briefly document what you've tried for each version in this markdown cell. You should describe what you've tried, a one sentence motivation for why you've tried it and what testing accuracy this version produced.\n",
    "\n",
    "#### Version 1\n",
    "\n",
    "*Your description goes here.*\n",
    "\n",
    "\n",
    "#### Version 2\n",
    "\n",
    "*Your description goes here.*\n",
    "\n",
    "...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

# Decision Trees & Random Forests

The lecture below by Patrick Winston gives a good first introduction into many
of the concepts used in Decision Trees, namely splitting the data set on a
specific attribute and measuring the resulting (dis)order of subsets.

### Identification Trees and Disorder

![embed](https://youtube.com/embed/SXBG3RGr_Rc)


<br/><br/>

These next few short videos by Victor Lavrenko give a more formal and more
complete picture of what a Decision Tree is and how exactly it is built. They
also cover the extensions to continuous features, regession and Random Forests.

### Decision Tree: How it works

![embed](https://youtube.com/embed/eKD5gxPPeY0)

### Decision Tree: ID3 Algorithm

![embed](https://youtube.com/embed/_XhOdSLlE5c)

### Decision Tree: Which attribute to split on?

![embed](https://youtube.com/embed/AmCV4g7_-QM)

### Decision Tree: Information Gain

![embed](https://youtube.com/embed/nodQ2s0CUbI)

### Decision Tree: Overfitting and pruning

![embed](https://youtube.com/embed/Q4NVG1IHQOU)

### Decision Tree: Continuous, multi-class and regression

![embed](https://youtube.com/embed/Jsn7hj7inlE)

### Decision Tree: Random Forests

![embed](https://youtube.com/embed/A-iqpbz7IDE)
